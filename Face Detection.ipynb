{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248ccbbf",
   "metadata": {},
   "source": [
    "# Face Recognition using CNN\n",
    "Step 1:\n",
    "At the first, you should input the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0692b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import np_utils\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a45a50",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "Load Dataset :\n",
    "After loading the Dataset you have to normalize every image.\n",
    "\n",
    "Note: an image is a Uint8 matrix of pixels and for calculation, you need to convert the format of the image to float or double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf835a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48.  49.  45. ...  47.  46.  46.]\n",
      " [ 60.  60.  62. ...  32.  34.  34.]\n",
      " [ 39.  44.  53. ...  29.  26.  29.]\n",
      " ...\n",
      " [114. 117. 114. ...  98.  96.  98.]\n",
      " [105. 105. 107. ...  54.  47.  41.]\n",
      " [116. 114. 117. ...  95. 100. 101.]]\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "# data = np.load('faces.npz')\n",
    "# data.head\n",
    "\n",
    "# load the \"Train Images\"\n",
    "path = 'faces/'\n",
    "x_train = np.load(path+'trainX.npy')\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28974bd8",
   "metadata": {},
   "source": [
    "# Normalize every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87b569e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1882353  0.19215687 0.1764706  ... 0.18431373 0.18039216 0.18039216]\n",
      " [0.23529412 0.23529412 0.24313726 ... 0.1254902  0.13333334 0.13333334]\n",
      " [0.15294118 0.17254902 0.20784314 ... 0.11372549 0.10196079 0.11372549]\n",
      " ...\n",
      " [0.44705883 0.45882353 0.44705883 ... 0.38431373 0.3764706  0.38431373]\n",
      " [0.4117647  0.4117647  0.41960785 ... 0.21176471 0.18431373 0.16078432]\n",
      " [0.45490196 0.44705883 0.45882353 ... 0.37254903 0.39215687 0.39607844]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train,dtype='float32')/255\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43b602f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data['testX']\n",
    "x_test = np.array(x_test,dtype='float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "872b7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Label of Images\n",
    "\n",
    "y_train= data['trainY']\n",
    "y_test= data['testY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5efad502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : {}\n",
      "x_train : [[0.1882353  0.19215687 0.1764706  ... 0.18431373 0.18039216 0.18039216]\n",
      " [0.23529412 0.23529412 0.24313726 ... 0.1254902  0.13333334 0.13333334]\n",
      " [0.15294118 0.17254902 0.20784314 ... 0.11372549 0.10196079 0.11372549]\n",
      " ...\n",
      " [0.44705883 0.45882353 0.44705883 ... 0.38431373 0.3764706  0.38431373]\n",
      " [0.4117647  0.4117647  0.41960785 ... 0.21176471 0.18431373 0.16078432]\n",
      " [0.45490196 0.44705883 0.45882353 ... 0.37254903 0.39215687 0.39607844]]\n",
      "Y-train shape: [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19]\n",
      "x_test shape: (160, 10304)\n"
     ]
    }
   ],
   "source": [
    "# show the train and test Data format\n",
    "print('x_train : {}'.format(x_train[:]))\n",
    "print('Y-train shape: {}'.format(y_train))\n",
    "print('x_test shape: {}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf01e1",
   "metadata": {},
   "source": [
    "\n",
    "# Step 3\n",
    "\n",
    "Split DataSet : Validation data and Train\n",
    "\n",
    "Validation DataSet: this data set is used to minimize overfitting.If the accuracy over the training data set increases, but the accuracy over then validation data set stays the same or decreases, then you're overfitting your neural network and you should stop training.\n",
    "\n",
    "Note: we usually use 30 percent of every dataset as the validation data but Here we only used 5 percent because the number of images in this dataset is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "794673de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid= train_test_split(\n",
    "    x_train, y_train, test_size=.05, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b766346",
   "metadata": {},
   "source": [
    "# Step 4Â¶\n",
    "\n",
    "For using the CNN, we need to change The size of images ( The size of images must be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f6410f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: 228\n",
      "x_test shape: (160,)\n"
     ]
    }
   ],
   "source": [
    "im_rows=112\n",
    "im_cols=92\n",
    "batch_size = 512\n",
    "im_shape = (im_rows, im_cols, 1)\n",
    "\n",
    "# Change the size of images\n",
    "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], *im_shape)\n",
    "\n",
    "print('x_train shape: {}'.format(y_train.shape[0]))\n",
    "print('x_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf9ec6",
   "metadata": {},
   "source": [
    "\n",
    "# Step 5\n",
    "\n",
    "Build CNN model: CNN have 3 main layer:\n",
    "\n",
    "    1. Convolutional layer\n",
    "    2. Pooling layer\n",
    "    3. Fully connected layer\n",
    "\n",
    "we could build a new architecture of CNN by changing the number and position of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f32be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
